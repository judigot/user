#!/bin/bash

# Keep this file up-to-date as soon as it's sourced, so any functions you run
# in the current shell session come from the latest `.snippetsrc`.
snippetsrcSelfUpdateOnSource() {
    # CI should test the checked-out version deterministically (no network mutation).
    if [ -n "${GITHUB_ACTIONS:-}" ]; then
        return 1
    fi

    if [ "${SNIPPETSRC_SELF_UPDATE_ATTEMPTED:-}" = "true" ]; then
        return 1
    fi

    SNIPPETSRC_SELF_UPDATE_ATTEMPTED="true"
    export SNIPPETSRC_SELF_UPDATE_ATTEMPTED

    local url="https://raw.githubusercontent.com/judigot/user/main/.snippetsrc"
    local tmp="$HOME/.snippetsrc.tmp.$$"

    if ! command -v curl >/dev/null 2>&1; then
        return 1
    fi

    if ! curl -fsSL --connect-timeout 2 --max-time 5 "$url" -o "$tmp" 2>/dev/null; then
        rm -f "$tmp" 2>/dev/null || true
        return 1
    fi

    if [ ! -s "$tmp" ]; then
        rm -f "$tmp" 2>/dev/null || true
        return 1
    fi

    if [ -f "$HOME/.snippetsrc" ] && cmp -s "$tmp" "$HOME/.snippetsrc" 2>/dev/null; then
        rm -f "$tmp" 2>/dev/null || true
        return 1
    fi

    mv "$tmp" "$HOME/.snippetsrc"

    SNIPPETSRC_SELF_UPDATED="true"
    export SNIPPETSRC_SELF_UPDATED

    # shellcheck source=/dev/null
    source "$HOME/.snippetsrc"
    return 0
}

if snippetsrcSelfUpdateOnSource; then
    return 0
fi

# Load aliases from ALIAS file
loadAliasFile() {
    local alias_file="${1:-$HOME/ALIAS}"
    [ ! -f "$alias_file" ] && return 1
    
    local current_func=""
    while IFS= read -r line || [ -n "$line" ]; do
        line="${line%%#*}"  # Remove comments
        line="${line%"${line##*[![:space:]]}"}"  # Trim trailing whitespace
        [ -z "$line" ] && continue
        
        if [[ "$line" == *: ]]; then
            current_func="${line%:}"
        elif [ -n "$current_func" ]; then
            alias "$line"="$current_func"
        fi
    done < "$alias_file"
}
loadAliasFile

helloWorld() {
    local user=${USER:-$USERNAME}
    echo -e "\e[32mHello, $user!\e[0m"
}

updateCurrentBranch() {
    git merge origin/main
    git push
}

# Original raw URL (kept for reference)
# [ -z "$USER_REPO_URL" ] && readonly USER_REPO_URL="https://raw.githubusercontent.com/judigot/user/main"

# Download user repo to temp directory, returns the path
downloadUserRepoTemp() {
    local url="https://github.com/judigot/user/archive/refs/heads/main.zip"

    if ! command -v curl >/dev/null 2>&1; then
        printf '%s\n' "curl is required to download the repo." >&2
        return 1
    fi

    if ! command -v unzip >/dev/null 2>&1; then
        printf '%s\n' "unzip is required to extract the repo." >&2
        return 1
    fi

    local tmp_dir
    tmp_dir=$(mktemp -d "/tmp/user-repo.XXXXXXXX") || return 1

    local zip="$tmp_dir/user.zip"

    if ! curl -fsSL --retry 3 --retry-delay 1 "$url" -o "$zip" 2>/dev/null; then
        printf '%s\n' "Download failed" >&2
        rm -rf "$tmp_dir" 2>/dev/null || true
        return 1
    fi

    if ! unzip -q "$zip" -d "$tmp_dir" 2>/dev/null; then
        # `unzip` failures are commonly caused by an HTML response being saved instead of a zip.
        # Don't hide the failure behind a generic message.
        printf '%s\n' "Extract failed (downloaded archive could not be unzipped)" >&2
        rm -rf "$tmp_dir" 2>/dev/null || true
        return 1
    fi

    rm -f "$zip" 2>/dev/null || true

    printf '%s\n' "$tmp_dir/user-main"
}

syncDotfiles() {
    local manifest="$1"
    local src="$2"
    local cleanup_dir=""
    
    if [ -z "$src" ]; then
        src=$(downloadUserRepoTemp) || return 1
        cleanup_dir=$(dirname "$src")
    fi
    
    local manifest_path="$src/$manifest"
    
    if [ ! -f "$manifest_path" ]; then
        echo "Manifest file not found: $manifest_path"
        [ -n "$cleanup_dir" ] && rm -rf "$cleanup_dir"
        return 1
    fi
    
    # Sync only what's listed in the manifest (handle files without trailing newline)
    while IFS= read -r file || [ -n "$file" ]; do
        if [ -n "$file" ]; then
            if [ -f "$src/$file" ]; then
                if [ "$(dirname "$file")" != "." ]; then
                    mkdir -p "$HOME/$(dirname "$file")" 2>/dev/null || true
                fi
                cp "$src/$file" "$HOME/$file" 2>/dev/null || true
            elif [ -d "$src/$file" ]; then
                mkdir -p "$HOME/$(dirname "$file")" 2>/dev/null || true
                cp -r "$src/$file" "$HOME/$file" 2>/dev/null || true
            fi
        fi
    done < "$manifest_path"
    
    [ -n "$cleanup_dir" ] && rm -rf "$cleanup_dir"
    echo "Dotfiles synced to home directory."
}

syncIDEFiles() {
    local src="$1"
    local cleanup_dir=""
    
    if [ -z "$src" ]; then
        src=$(downloadUserRepoTemp) || return 1
        cleanup_dir=$(dirname "$src")
    fi
    
    local appdata="$HOME/AppData/Roaming"
    local cursor_user="$appdata/Cursor/User"
    local zed_dir="$appdata/Zed"
    
    mkdir -p "$cursor_user/snippets" "$zed_dir"
    
    # Original: curl -sL "$USER_REPO_URL/ide/cursor/..." -o "..."
    cp "$src/ide/cursor/settings.jsonc" "$cursor_user/settings.json"
    cp "$src/ide/cursor/keybindings.jsonc" "$cursor_user/keybindings.json"
    cp "$src/ide/cursor/Master of Snippets.code-snippets" "$cursor_user/snippets/Master of Snippets.code-snippets"
    cp "$src/ide/zed/settings.jsonc" "$zed_dir/settings.json"
    cp "$src/ide/zed/keymap.jsonc" "$zed_dir/keymap.json"
    
    [ -n "$cleanup_dir" ] && rm -rf "$cleanup_dir"
    echo "IDE files synced."
}

syncUbuntu() {
    local manifest="$1"
    local src="$2"
    local cleanup_dir=""
    local wsl_root="//wsl.localhost/Ubuntu/root"
    local wsl_user="//wsl.localhost/Ubuntu/home/$USER"
    
    if [ ! -d "$wsl_root" ]; then
        echo "WSL Ubuntu not accessible, skipping."
        return 0
    fi
    
    if [ -z "$src" ]; then
        src=$(downloadUserRepoTemp) || return 1
        cleanup_dir=$(dirname "$src")
    fi
    
    local manifest_path="$src/$manifest"
    
    if [ ! -f "$manifest_path" ]; then
        echo "Manifest file not found: $manifest_path"
        [ -n "$cleanup_dir" ] && rm -rf "$cleanup_dir"
        return 1
    fi
    
    # Function to sync a single entry
    sync_entry() {
        local entry="$1"
        local dest_base="$2"
        
        # If entry starts with $HOME, it's a Windows path to sync to WSL home
        if echo "$entry" | grep -q '^\$HOME'; then
            # Expand $HOME and convert Windows path format
            local win_path=$(echo "$entry" | sed "s|\$HOME|$HOME|g" | sed 's|\\|/|g')
            # Extract just the relative path from $HOME (e.g., .ssh from $HOME\.ssh)
            local rel_path=$(echo "$entry" | sed 's|^\$HOME[\\/]*||' | sed 's|\\|/|g')
            local wsl_dest="$dest_base/$rel_path"
            
            # Copy from Windows to WSL
            if [ -d "$win_path" ]; then
                # Copy contents into destination (merge, don't replace)
                mkdir -p "$wsl_dest" 2>/dev/null || true
                cp -r "$win_path/." "$wsl_dest/" 2>/dev/null || true
            elif [ -f "$win_path" ]; then
                mkdir -p "$(dirname "$wsl_dest")" 2>/dev/null || true
                cp "$win_path" "$wsl_dest" 2>/dev/null || true
            fi
        else
            # Regular file from repo
            if [ -d "$src/$entry" ]; then
                mkdir -p "$dest_base/$entry" 2>/dev/null || true
                cp -r "$src/$entry/." "$dest_base/$entry/" 2>/dev/null || true
            elif [ -f "$src/$entry" ]; then
                mkdir -p "$dest_base/$(dirname "$entry")" 2>/dev/null || true
                cp "$src/$entry" "$dest_base/$entry" 2>/dev/null || true
            fi
        fi
    }
    
    # Sync only what's listed in the manifest (handle files without trailing newline)
    while IFS= read -r file || [ -n "$file" ]; do
        [ -n "$file" ] && sync_entry "$file" "$wsl_root"
    done < "$manifest_path"
    
    # Sync to user home if available
    if [ -d "$wsl_user" ]; then
        while IFS= read -r file || [ -n "$file" ]; do
            [ -n "$file" ] && sync_entry "$file" "$wsl_user"
        done < "$manifest_path"
    fi
    
    [ -n "$cleanup_dir" ] && rm -rf "$cleanup_dir"
    echo "Ubuntu WSL synced."
}

sourceShellConfig() {
    # Source the appropriate configuration based on the current shell
    if [[ "$0" == *"zsh"* ]]; then
        [[ -f "$HOME/.zshrc" ]] && source "$HOME/.zshrc"
    elif [[ "$0" == *"bash"* ]]; then
        [[ -f "$HOME/.bashrc" ]] && source "$HOME/.bashrc"
    fi

    # Source the shared snippets configuration
    [[ -f "$HOME/.snippetsrc" ]] && source "$HOME/.snippetsrc"
}

syncSnippetsrcAndAliasFromRemote() {
    if [ -n "${GITHUB_ACTIONS:-}" ] && [ -n "${GITHUB_WORKSPACE:-}" ] && [ -f "$GITHUB_WORKSPACE/.snippetsrc" ] && [ -f "$GITHUB_WORKSPACE/ALIAS" ]; then
        cp "$GITHUB_WORKSPACE/.snippetsrc" "$HOME/.snippetsrc" && cp "$GITHUB_WORKSPACE/ALIAS" "$HOME/ALIAS"
        return $?
    fi

    if command -v downloadGithubFiles >/dev/null 2>&1; then
        if downloadGithubFiles judigot/user ".snippetsrc" "ALIAS" --dest "$HOME" --branch "main" >/dev/null 2>&1; then
            return 0
        fi
    fi

    curl -fsSL "https://raw.githubusercontent.com/judigot/user/main/.snippetsrc" -o "$HOME/.snippetsrc" \
        && curl -fsSL "https://raw.githubusercontent.com/judigot/user/main/ALIAS" -o "$HOME/ALIAS"
}

updateUserEnv() {
    isWindowsLikeShell() {
        case "$(uname -s 2>/dev/null)" in
            MINGW*|MSYS*|CYGWIN*) return 0 ;;
            *) return 1 ;;
        esac
    }

    hasApportableRoot() {
        if isWindowsLikeShell && [ -d "C:/apportable" ]; then
            return 0
        fi

        [ -d "/c/apportable" ] || [ -d "/mnt/c/apportable" ]
    }

    # Self-heal: even old versions of `.snippetsrc` should be able to pull the latest
    # updater logic from GitHub, then re-run once using the refreshed definitions.
    if [ "${UPDATER_SELF_REFRESHED:-}" != "true" ]; then
        if syncSnippetsrcAndAliasFromRemote; then
            UPDATER_SELF_REFRESHED="true"
            export UPDATER_SELF_REFRESHED

            # shellcheck source=/dev/null
            . "$HOME/.snippetsrc"

            updateUserEnv "$@"
            return $?
        fi
    fi

    # Non-Windows: only keep `.snippetsrc` + `ALIAS` fresh.
    if ! isWindowsLikeShell; then
        # shellcheck source=/dev/null
        [ -f "$HOME/.snippetsrc" ] && source "$HOME/.snippetsrc"

        echo "Terminal files updated and sourced successfully."
        return 0
    fi

    # If Apportable isn't present, only refresh terminal essentials.
    if ! hasApportableRoot; then
        if ! downloadGithubFiles judigot/user ".bashrc" ".snippetsrc" "ALIAS" --dest "$HOME" --branch "main" >/dev/null 2>&1; then
            syncSnippetsrcAndAliasFromRemote || true
            curl -fsSL "https://raw.githubusercontent.com/judigot/user/main/.bashrc" -o "$HOME/.bashrc" 2>/dev/null || true
        fi
        sourceShellConfig
        echo "Terminal files updated and sourced successfully."
        return 0
    fi

    local src
    src=$(downloadUserRepoTemp) || {
        # If the full repo archive can't be downloaded/unzipped, fall back to raw-per-file
        # syncing so incomplete Windows machines still get the commit-and-sync style behavior.
        syncSnippetsrcAndAliasFromRemote || true

        # Dotfiles (exclude terminal files since they are managed separately)
        downloadGithubFiles judigot/user ".bash_profile" ".profile" ".zshrc" "profile.ps1" "PATH" "Apportable.ps1" "Apportable.sh" --dest "$HOME" --branch "main" >/dev/null 2>&1 || true

        # IDE files into AppData
        mkdir -p "$HOME/AppData/Roaming/Cursor/User/snippets" "$HOME/AppData/Roaming/Zed" 2>/dev/null || true
        downloadGithubFiles judigot/user "ide/cursor/settings.jsonc" "ide/cursor/keybindings.jsonc" "ide/cursor/Master of Snippets.code-snippets" --dest "/tmp/ide-tmp" --branch "main" >/dev/null 2>&1 || true
        downloadGithubFiles judigot/user "ide/zed/settings.jsonc" "ide/zed/keymap.jsonc" --dest "/tmp/ide-tmp" --branch "main" >/dev/null 2>&1 || true

        cp "/tmp/ide-tmp/ide/cursor/settings.jsonc" "$HOME/AppData/Roaming/Cursor/User/settings.json" 2>/dev/null || true
        cp "/tmp/ide-tmp/ide/cursor/keybindings.jsonc" "$HOME/AppData/Roaming/Cursor/User/keybindings.json" 2>/dev/null || true
        cp "/tmp/ide-tmp/ide/cursor/Master of Snippets.code-snippets" "$HOME/AppData/Roaming/Cursor/User/snippets/Master of Snippets.code-snippets" 2>/dev/null || true
        cp "/tmp/ide-tmp/ide/zed/settings.jsonc" "$HOME/AppData/Roaming/Zed/settings.json" 2>/dev/null || true
        cp "/tmp/ide-tmp/ide/zed/keymap.jsonc" "$HOME/AppData/Roaming/Zed/keymap.json" 2>/dev/null || true
        rm -rf "/tmp/ide-tmp" 2>/dev/null || true

        sourceShellConfig
        echo "Updater fallback: synced via raw downloads, repo zip unavailable."
        return 0
    }

    # Apportable exists: avoid overwriting terminal files. Keep any Windows-specific
    # terminal customization intact, while still syncing other dotfiles.
    local dotfiles_manifest_in="$src/DOTFILES"
    local dotfiles_manifest_tmp="$src/.dotfiles.no-terminal.$$"

    if [ -f "$dotfiles_manifest_in" ]; then
        awk '
            $0 != ".bashrc" && $0 != ".snippetsrc" && $0 != "ALIAS" && $0 != "" { print $0 }
        ' "$dotfiles_manifest_in" > "$dotfiles_manifest_tmp"
        syncDotfiles "$(basename "$dotfiles_manifest_tmp")" "$src"
    else
        syncDotfiles "DOTFILES" "$src"
    fi
    syncIDEFiles "$src"
    syncUbuntu "UBUNTU" "$src"

    rm -rf "$(dirname "$src")"

    sourceShellConfig
    echo "Configuration files updated and sourced successfully."
}

bigBangVite() {
    curl -L "https://raw.githubusercontent.com/judigot/user/main/BigBangVite.sh" | bash
}

bigBangLaravel() {
    curl -L "https://raw.githubusercontent.com/judigot/user/main/BigBangLaravel.sh" | bash
}

logSSH() {
    echo -e "Copy and paste the public key below to your GitHub account:\n\n\e[32m$(cat ~/.ssh/id_ed25519.pub) \e[0m\n" # Green
}

generateSSHKey() {
    ssh-keygen -t rsa -f ~/.ssh/id_ed25519 -P "" && clear && logSSH
    ssh-keygen -t rsa -f ~/.ssh/id_ed25519 -P "" && chmod 600 ~/.ssh/id_ed25519 && clear && echossh
}

testSSH() {
    ssh -T git@github.com -o StrictHostKeyChecking=no
}

useSSHKey() {
  key="$1"

  # Start agent if needed
  if [ -z "${SSH_AUTH_SOCK:-}" ] || ! ssh-add -l >/dev/null 2>&1; then
    eval "$(ssh-agent -s)" >/dev/null
  fi

  # Reset keys, then add personal
  ssh-add -D >/dev/null 2>&1 || true
  ssh-add "$HOME/.ssh/$key"

  # Quick confirmation
  ssh-add -l
}

usePersonalSSH() { useSSHKey "id_ed25519"; }

useWorkSSH() { useSSHKey "id_ed25519_work"; }

deleteAll() {
    read -rp 'Are you sure you want to delete everything? (y/N) ' confirm
    [ "$confirm" = 'y' ] && rm -rf .[!.]* *
}

loadSnippets() {
    grep -q '#<SNIPPETS>' "$HOME/.bashrc" 2>/dev/null || printf '%s\n' '#<SNIPPETS>' '[[ -f "$HOME/.snippetsrc" ]] && source "$HOME/.snippetsrc"' '#</SNIPPETS>' >> "$HOME/.bashrc"
}

installClaudeCode() {
    case "$(uname -s)" in
        Linux*|Darwin*)
            curl -fsSL https://claude.ai/install.sh | bash
            ;;
        MINGW*|MSYS*|CYGWIN*)
            # Windows workaround (official installer is corrupted)
            powershell.exe -Command '
                $GCS_BUCKET = "https://storage.googleapis.com/claude-code-dist-86c565f3-f756-42ad-8dfa-d59b1c096819/claude-code-releases"
                $version = Invoke-RestMethod -Uri "$GCS_BUCKET/stable"
                $platform = "win32-x64"
                New-Item -ItemType Directory -Force -Path "$env:USERPROFILE\.local\bin" | Out-Null
                Invoke-WebRequest -Uri "$GCS_BUCKET/$version/$platform/claude.exe" -OutFile "$env:USERPROFILE\.local\bin\claude.exe"
                Write-Host "Installed claude.exe to ~/.local/bin/"
            '
            ;;
        *)
            echo "Unsupported OS: $(uname -s)"
            return 1
            ;;
    esac
}

claude() {
    if [ ! -d ~/ai ]; then
        git clone git@github.com:judigot/ai.git ~/ai >/dev/null 2>&1
    else
        git -C ~/ai pull >/dev/null 2>&1
    fi

    command claude --plugin-dir ~/ai --plugin-dir . "$@"
}

addCursorBoilerplate() {
    downloadGithubRepo judigot/cursor
}

# Download GitHub repo without cloning (no .git)
# Usage: downloadGithubRepo <user/repo> [branch] [target_dir]
# Example: downloadGithubRepo judigot/cursor main .
downloadGithubRepo() {
    local repo="$1"
    local branch="${2:-main}"
    local target="${3:-.}"
    
    if [ -z "$repo" ]; then
        echo "Usage: downloadGithubRepo <user/repo> [branch] [target_dir]"
        return 1
    fi
    
    local name="${repo#*/}"
    local url="https://github.com/$repo/archive/refs/heads/$branch.zip"

    local tmp_dir
    tmp_dir=$(mktemp -d "/tmp/${name}.XXXXXXXX") || return 1

    local zip="$tmp_dir/$name.zip"

    if ! curl -fsSL --retry 3 --retry-delay 1 "$url" -o "$zip" 2>/dev/null; then
        printf '%s\n' "Download failed" >&2
        rm -rf "$tmp_dir" 2>/dev/null || true
        return 1
    fi

    if [ ! -s "$zip" ]; then
        printf '%s\n' "Download failed (empty archive)" >&2
        rm -rf "$tmp_dir" 2>/dev/null || true
        return 1
    fi

    if ! unzip -q "$zip" -d "$tmp_dir" 2>/dev/null; then
        printf '%s\n' "Extract failed" >&2
        rm -rf "$tmp_dir" 2>/dev/null || true
        return 1
    fi
    
    mv "$tmp_dir/$name-$branch"/* "$target/" 2>/dev/null
    mv "$tmp_dir/$name-$branch"/.[!.]* "$target/" 2>/dev/null
    rm -rf "$tmp_dir"
    
    echo "Downloaded $repo to $target"
}

# Download files from GitHub repo (no caching issues, supports nested paths)
# Usage: downloadGithubFiles <user/repo> [files...] [--dest dir] [--branch name]
# Example: downloadGithubFiles judigot/user .bashrc .zshrc .snippetsrc
# Example: downloadGithubFiles judigot/user src/index.ts --dest ./src --branch develop
downloadGithubFiles() {
    local repo=""
    local dest="."
    local branch="main"
    local files=()
    
    while [ $# -gt 0 ]; do
        case "$1" in
            --dest) dest="$2"; shift 2 ;;
            --branch) branch="$2"; shift 2 ;;
            *)
                if [ -z "$repo" ]; then
                    repo="$1"
                else
                    files+=("$1")
                fi
                shift ;;
        esac
    done
    
    if [ -z "$repo" ] || [ ${#files[@]} -eq 0 ]; then
        echo "Usage: downloadGithubFiles <user/repo> [files...] [--dest dir] [--branch name]"
        return 1
    fi
    
    downloadRawFile() {
        local raw_repo="$1"
        local raw_branch="$2"
        local raw_file="$3"
        local raw_dest="$4"

        local cache_bust=""
        cache_bust=$(date +%s 2>/dev/null || echo "0")

        mkdir -p "$(dirname "$raw_dest")"
        curl -fsSL -H "Cache-Control: no-cache" -H "Pragma: no-cache" \
            "https://raw.githubusercontent.com/$raw_repo/$raw_branch/$raw_file?cachebust=$cache_bust" \
            -o "$raw_dest" 2>/dev/null
    }

    # Prefer zip-based download (fewer requests), but fall back to raw-per-file
    # in networks where GitHub archive downloads are blocked/rewritten.
    local name="${repo#*/}"
    local url="https://github.com/$repo/archive/refs/heads/$branch.zip"

    local tmp_dir=""
    tmp_dir=$(mktemp -d "/tmp/${name}.XXXXXXXX" 2>/dev/null) || tmp_dir=""

    if [ -n "$tmp_dir" ] && command -v unzip >/dev/null 2>&1; then
        local zip="$tmp_dir/$name.zip"

        if curl -fsSL --retry 3 --retry-delay 1 "$url" -o "$zip" 2>/dev/null && [ -s "$zip" ] && unzip -q "$zip" -d "$tmp_dir" 2>/dev/null; then
            local src="$tmp_dir/$name-$branch"

            for file in "${files[@]}"; do
                [ -n "$file" ] || continue
                local dest_path="$dest/$file"
                mkdir -p "$(dirname "$dest_path")"
                cp "$src/$file" "$dest_path" 2>/dev/null
            done

            rm -rf "$tmp_dir"
            echo "Downloaded ${#files[@]} file(s) to $dest"
            return 0
        fi

        rm -rf "$tmp_dir" 2>/dev/null || true
    fi

    # Raw fallback
    local downloaded=0
    for file in "${files[@]}"; do
        [ -n "$file" ] || continue
        local dest_path="$dest/$file"
        if downloadRawFile "$repo" "$branch" "$file" "$dest_path"; then
            downloaded=$((downloaded + 1))
        else
            printf '%s\n' "Download failed: $file" >&2
            return 1
        fi
    done

    echo "Downloaded ${downloaded} file(s) to $dest"
}

#<TERMUX>
termuxInstallUbuntu() {
    pkg update -y && pkg upgrade -y
    pkg install -y proot-distro
    proot-distro install ubuntu
}

termuxLoginUbuntu() {
    proot-distro login ubuntu
}
#</TERMUX>

#<AGENT_ALIASES>
gc() { git add -A && git status && git commit -m "$1"; }  # Git commit: stage all, show status, commit with message (no push)
gcp() { git add -A && git status; }                       # Git commit preview: stage all and show what would be committed
gpr() { gh pr create --fill; }                            # GitHub PR: create pull request with auto-filled title/body
nr() { bun run "$1"; }                                    # Node run: execute a script from package.json using Bun
#</AGENT_ALIASES>